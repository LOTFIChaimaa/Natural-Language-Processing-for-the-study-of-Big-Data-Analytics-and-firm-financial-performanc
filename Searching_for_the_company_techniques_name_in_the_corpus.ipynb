{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Searching for the company_techniques name in the corpus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFrW-UVbficX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056da37a-a30b-4b1d-ae46-69dabd8f2e86"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNk2auDfp8r"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmjXWYQuCnup"
      },
      "source": [
        "PDF TO TEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlB-5pxdfHxV"
      },
      "source": [
        "import tika\n",
        "tika.initVM()\n",
        "from tika import parser\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "fichiers = [f for f in listdir('/content/gdrive/MyDrive/Target22') if isfile(join('/content/gdrive/MyDrive/Target22', f))]\n",
        "\n",
        "for i in range(len(fichiers)):\n",
        "    path = '/content/gdrive/MyDrive/Target22/{}'.format(fichiers[i])\n",
        "    parsed = parser.from_file(path)\n",
        "    #print(parsed[\"metadata\"])\n",
        "    #print(parsed[\"content\"])\n",
        "    base = os.path.splitext(fichiers[i])[0]\n",
        "    file = open(\"/content/gdrive/MyDrive/targetTexts/{}.txt\".format(base), \"w\", encoding='utf-8')\n",
        "    file.write(parsed[\"content\"] )\n",
        "    file.close\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57Dh_u1sG3sJ"
      },
      "source": [
        "***MODULE 4***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moiZsgYHJxol"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "fichiers1 = [f for f in listdir('/content/gdrive/MyDrive/test1') if isfile(join('/content/gdrive/MyDrive/test1', f))]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzJA9897DitP"
      },
      "source": [
        "def search_string_in_file(file_name, string_to_search):\n",
        "    l=[]\n",
        "    line_number = 0\n",
        "    with open(file_name , 'r') as read_obj:\n",
        "      for line in read_obj:\n",
        "        line_number += 1\n",
        "        if string_to_search in line:\n",
        "          l.append((line_number, line.rstrip()))\n",
        "    return l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pTxZTQvOpWC"
      },
      "source": [
        "# files = [f for f in listdir('/content/gdrive/MyDrive/test3Texts') if isfile(join('/content/gdrive/MyDrive/test3Texts', f))]\n",
        " \n",
        "companies = ['3M Company', 'A.O.Smith Corporation', 'Abbott Laboratories', 'Abbvie Inc.', 'Accenture Public Limited', 'Activision Blizzard Inc.',\n",
        "            'Advance Auto Parts Inc.', 'Advanced Micro Devices Inc.', 'Aflac Inc', 'Accenture' ]\n",
        "\n",
        "techniques = ['Association analysis', 'Market Basket Analysis', 'Cooccurence Grouping', 'Association Rule Mining', 'Association Discovery', \n",
        "                'Sequence analysis', 'Sequential Pattern Mining', 'Clustering', 'Cluster analysis', 'Similarity matching', 'Link analysis',\n",
        "              'decision tree', 'decision trees', 'neural networks']\n",
        "\n",
        "# techniques =  ['Partial Least Squares Regression', 'LARS', 'Random Forest', 'Gradient Boosting',  'Suport Vector Machines',\n",
        "#  'Genetic Algorithms', 'Prescriptive Analytics', 'Stochastic Optimization', 'Optimization', 'Multi Criteria Decision Making Techniques'\n",
        "#  , 'Decision Modeling', 'Network Science', 'Simulation Techniques', 'Deep Learning', 'Artificial Intelligence']\n",
        "for i in range(1):\n",
        "  path = '/content/Accenture-Digital-Supply-Chain-Operations-Analytics-POV.txt'\n",
        "  for company in companies:\n",
        "    line = search_string_in_file(path, company)\n",
        "    if line:\n",
        "      for technique in techniques:\n",
        "        line1 = search_string_in_file(path, technique)\n",
        "        if line1 != []:\n",
        "            print( line, line1)\n",
        "\n",
        "    else:\n",
        "      # print(\"No match\")\n",
        "      pass\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW5phNElElfk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOMHiQ_Nx4Y7",
        "outputId": "73cbbc1b-1c0f-4362-d0c9-1459e3fdd568"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "files = [f for f in listdir('/content/gdrive/MyDrive/test5Texts') if isfile(join('/content/gdrive/MyDrive/test5Texts', f))]\n",
        "\n",
        "companies =  ['NEWS CORPORATION', 'NEXTERA ENERGY', 'NIELSEN HOLDINGS PLC', 'NIKE', 'NORFOLK SOUTHERN CORPORATION', 'NORTHERN TRUST CORPORATION', \n",
        "              'Northrop Grumman Corporation', 'NORWEGIAN CRUISE LINE HOLDINGS', 'NUCOR CORPORATION', 'NVIDIA CORPORATION']\n",
        "techniques = ['Descriptive Analytics', 'Predictive Analytics', 'Prescriptive Analytics', 'Association analysis', 'Market Basket Analysis', 'Cooccurence Grouping', 'Association Rule Mining', 'Association Discovery', \n",
        "                'Sequence analysis', 'Sequential Pattern Mining', 'Clustering', 'Cluster analysis', 'Similarity matching', 'Link analysis',\n",
        "              'decision tree', 'decision trees', 'neural networks', 'neural network','Partial Least Squares Regression', 'LARS', 'Random Forest', 'Gradient Boosting',  'Suport Vector Machines',\n",
        " 'Genetic Algorithms', 'Prescriptive Analytics', 'Stochastic Optimization', 'Optimization', 'Multi Criteria Decision Making Techniques'\n",
        " , 'Decision Modeling', 'Network Science', 'Simulation Techniques', 'Deep Learning', 'Artificial Intelligence']\n",
        "\n",
        "for i in range(len(files)):\n",
        "  path = '/content/gdrive/MyDrive/test5Texts/{}'.format(files[i])\n",
        "  for company in companies:\n",
        "    line = search_string_in_file(path, company)\n",
        "    if line:\n",
        "      for technique in techniques:\n",
        "        line1 = search_string_in_file(path, technique)\n",
        "        if line1 != []:\n",
        "            print( 'company', company, 'tec', technique)\n",
        "            \n",
        "    else:\n",
        "      #line1 = 0\n",
        "      #print(\"No match\")\n",
        "      pass\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "company TEAM tec Artificial Intelligence\n",
            "company AUTOLIV tec Optimization\n",
            "company AUTOLIV tec Artificial Intelligence\n",
            "company TEAM tec LARS\n",
            "company NIKE tec decision tree\n",
            "company NIKE tec decision trees\n",
            "company NIKE tec neural networks\n",
            "company NIKE tec neural network\n",
            "company NIKE tec Deep Learning\n",
            "company NIKE tec Artificial Intelligence\n",
            "company TEAM tec Artificial Intelligence\n",
            "company The Travelers Companies tec Clustering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jgza5fhsReq"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "files = [f for f in listdir('/content/gdrive/MyDrive/test111Texts') if isfile(join('/content/gdrive/MyDrive/test111Texts', f))]\n",
        "\n",
        "companies = ['DARDEN RESTAURANTS','DEERE & COMPANY','DELTA AIR LINES', 'DEVON ENERGY CORPORATION', 'DISCOVER FINANCIAL SERVICES',\n",
        "'DISH NETWORK CORPORATION','DOLLAR GENERAL CORPORATION','DOLLAR TREE', 'DOVER CORPORATION','DTE ENERGY COMPANY',\n",
        "'DUKE ENERGY CORPORATION','E*TRADE FINANCIAL CORPORATION','EASTMAN CHEMICAL COMPANY', 'EATON CORPORATION PUBLIC LIMITED COMPA',\n",
        "'EBAY','ECOLAB','EDISON INTERNATIONAL','EDWARDS LIFESCIENCES CORPORATION','ELECTRONIC ARTS','ELI LILLY AND COMPANY',\n",
        "'EMERSON ELECTRIC CO','ENTERGY CORPORATION','EOG RESOURCES', 'EQUIFAX','EVEREST RE GROUP','Eversource Energy',\n",
        "'EXELON CORPORATION','EXPEDITORS INTERNATIONAL OF WASHINGTON','EXXON MOBIL CORPORATION','F5 NETWORKS', 'FACEBOOK',\n",
        "'FASTENAL COMPANY','FEDEX CORPORATION','FIDELITY NATIONAL INFORMATION SERVICES','FIFTH THIRD BANCORP','FIRST REPUBLIC BANK','FIRSTENERGY CORP',\n",
        "'FISERV','FLEETCOR TECHNOLOGIES','FLIR SYSTEMS','FLOWSERVE CORPORATION','FMC CORPORATION','FORD MOTOR COMPANY',\n",
        "'FORTINET', 'FORTUNE BRANDS HOME & SECURITY', 'FRANKLIN RESOURCES', 'FREEPORT-MCMORAN','Garmin', 'GARTNER', 'GENERAL DYNAMICS CORPORATION']\n",
        "\n",
        "techniques = ['Descriptive Analytics', 'Predictive Analytics', 'Prescriptive Analytics', 'Association analysis', 'Market Basket Analysis', 'Cooccurence Grouping', 'Association Rule Mining', 'Association Discovery', \n",
        "                'Sequence analysis', 'Sequential Pattern Mining', 'Clustering', 'Cluster analysis', 'Similarity matching', 'Link analysis',\n",
        "              'decision tree', 'decision trees', 'neural networks', 'neural network','Partial Least Squares Regression', 'LARS', 'Random Forest', 'Gradient Boosting',  'Suport Vector Machines',\n",
        " 'Genetic Algorithms', 'Prescriptive Analytics', 'Stochastic Optimization', 'Optimization', 'Multi Criteria Decision Making Techniques'\n",
        " , 'Decision Modeling', 'Network Science', 'Simulation Techniques', 'Deep Learning', 'Artificial Intelligence']\n",
        "\n",
        "for i in range(len(files)):\n",
        "  path = '/content/gdrive/MyDrive/test111Texts/{}'.format(files[i])\n",
        "  for company in companies:\n",
        "    line = search_string_in_file(path, company)\n",
        "    if line:\n",
        "      for technique in techniques:\n",
        "        line1 = search_string_in_file(path, technique)\n",
        "        if line1 != []:\n",
        "            print(files[i], 'Company', company, 'tech;', technique, line, line1)\n",
        "            \n",
        "    else:\n",
        "      #line1 = 0\n",
        "      #print(\"No match\")\n",
        "      pass\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-n8CU2DaId5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaavrMCisViM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fe3176-6ee1-46cb-c4c5-8dbabe7e5866"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "files = [f for f in listdir('/content/gdrive/MyDrive/test0Texts') if isfile(join('/content/gdrive/MyDrive/test0Texts', f))]\n",
        "\n",
        "# companies = ['3M Company', 'A.O.Smith Corporation', 'Abbott Laboratories', 'Abbvie Inc.', 'Accenture Public Limited', 'Activision Blizzard Inc.',\n",
        "#             'Advance Auto Parts', 'Advanced Micro Devices', 'Aflac Inc', 'Accenture', 'AGILENT TECHNOLOGIES ', 'AIR PRODUCTS AND CHEMICALS', 'AKAMAI TECHNOLOGIES',  'ALBEMARLE CORPORATION',\n",
        "# 'ALEXION PHARMACEUTICALS',  'Allergan plc', 'ALLIANT ENERGY CORPORATION', 'ALPHABET', 'Altria Group', 'AMAZON',\n",
        "# 'AMEREN CORPORATION', 'AMERICAN AIRLINES GROUP', 'AMERICAN ELECTRIC POWER COMPANY', 'AMERICAN EXPRESS COMPANY'\n",
        "# 'AMERICAN INTERNATIONAL GROUP', 'AMERICAN WATER WORKS COMPANY', 'AMERIPRISE FINANCIAL',  'AMERISOURCEBERGEN CORPORATION'\n",
        "# 'AMETEK', 'AMGEN', 'AMPHENOL CORPORATION', 'ANALOG DEVICES', 'ANSYS',  'ANTHEM',  'AON',\n",
        "# 'APACHE CORPORATION', 'APPLE', 'APPLIED MATERIALS', 'ARCHER-DANIELS-MIDLAND COMPANY',\n",
        "# 'ARTHUR J. GALLAGHER & CO', 'ASSURANT', 'AT&T', 'AUTODESK', 'AUTOMATIC DATA PROCESSING','AUTOZONE', 'AVERY DENNISON CORPORATION',\n",
        "# 'BALL CORPORATION', 'BANK OF AMERICA CORPORATION', 'BAXTER INTERNATIONAL', 'BECTON', 'DICKINSON AND COMPANY']\n",
        "\n",
        "companies = ['NEWS CORPORATION', 'NEXTERA ENERGY', 'NIELSEN HOLDINGS PLC', 'NIKE', 'NORFOLK SOUTHERN CORPORATION', 'NORTHERN TRUST CORPORATION', \n",
        "              'Northrop Grumman Corporation', 'NORWEGIAN CRUISE LINE HOLDINGS', 'NUCOR CORPORATION', 'NVIDIA CORPORATION']\n",
        "\n",
        "techniques = ['Descriptive Analytics', 'Predictive Analytics', 'Prescriptive Analytics', 'Association analysis', 'Market Basket Analysis', 'Cooccurence Grouping', 'Association Rule Mining', 'Association Discovery', \n",
        "                'Sequence analysis', 'Sequential Pattern Mining', 'Clustering', 'Cluster analysis', 'Similarity matching', 'Link analysis',\n",
        "              'decision tree', 'decision trees', 'neural networks', 'neural network','Partial Least Squares Regression', 'LARS', 'Random Forest', 'Gradient Boosting',  'Suport Vector Machines',\n",
        " 'Genetic Algorithms', 'Prescriptive Analytics', 'Stochastic Optimization', 'Optimization', 'Multi Criteria Decision Making Techniques'\n",
        " , 'Decision Modeling', 'Network Science', 'Simulation Techniques', 'Deep Learning', 'Artificial Intelligence']\n",
        "\n",
        "for i in range(len(files)):\n",
        "  path = '/content/gdrive/MyDrive/test0Texts/{}'.format(files[i])\n",
        "  for company in companies:\n",
        "    line = search_string_in_file(path, company)\n",
        "    if line:\n",
        "      for technique in techniques:\n",
        "        line1 = search_string_in_file(path, technique)\n",
        "        if line1 != []:\n",
        "            print(files[i], ' Company ', company, ' Technique ', technique, line,  line1)\n",
        "            \n",
        "    else:\n",
        "      #line1 = 0\n",
        "      #print(\"No match\")\n",
        "      pass\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE RAISE OF DATA ANALYTICS AND DATA-LEAD DECISION MAKING IN GLOBAL SPORTING ORGANIZATIONS.txt  Company  BLACKROCK  Technique  Cluster analysis [(4567, 'BLACKROCK Expert Services Group')] [(1292, 'Cluster analysis is applied to determine segments')]\n",
            "THE RAISE OF DATA ANALYTICS AND DATA-LEAD DECISION MAKING IN GLOBAL SPORTING ORGANIZATIONS.txt  Company  BLACKROCK  Technique  decision tree [(4567, 'BLACKROCK Expert Services Group')] [(11298, 'survey, questionnaire, web-application, decision tree'), (11327, 'like a decision tree. Each question is essentially a'), (11353, 'integrate this survey decision tree tool.')]\n",
            "THE RAISE OF DATA ANALYTICS AND DATA-LEAD DECISION MAKING IN GLOBAL SPORTING ORGANIZATIONS.txt  Company  BLACKROCK  Technique  neural networks [(4567, 'BLACKROCK Expert Services Group')] [(16019, 'based on neural networks were introduced using the')]\n",
            "THE RAISE OF DATA ANALYTICS AND DATA-LEAD DECISION MAKING IN GLOBAL SPORTING ORGANIZATIONS.txt  Company  BLACKROCK  Technique  neural network [(4567, 'BLACKROCK Expert Services Group')] [(16019, 'based on neural networks were introduced using the')]\n",
            "THE RAISE OF DATA ANALYTICS AND DATA-LEAD DECISION MAKING IN GLOBAL SPORTING ORGANIZATIONS.txt  Company  BLACKROCK  Technique  Optimization [(4567, 'BLACKROCK Expert Services Group')] [(242, 'Impact of Digital Supported Process Workflow Optimization for Knee Joint Endoprosthesis'), (8302, 'LAHMANN, Benjamin. 2019. Impact of Digital Supported Process Workflow Optimization for Knee Joint')]\n",
            "THE RAISE OF DATA ANALYTICS AND DATA-LEAD DECISION MAKING IN GLOBAL SPORTING ORGANIZATIONS.txt  Company  BLACKROCK  Technique  Artificial Intelligence [(4567, 'BLACKROCK Expert Services Group')] [(9273, 'The relationship between Artificial Intelligence (AI)')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKgyDX9QsZyo"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "files = [f for f in listdir('/content/gdrive/MyDrive/test1Texts') if isfile(join('/content/gdrive/MyDrive/test1Texts', f))]\n",
        "\n",
        "# companies = ['3M Company', 'A.O.Smith Corporation', 'Abbott Laboratories', 'Abbvie Inc.', 'Accenture Public Limited', 'Activision Blizzard Inc.',\n",
        "#             'Advance Auto Parts', 'Advanced Micro Devices', 'Aflac Inc', 'Accenture', 'AGILENT TECHNOLOGIES ', 'AIR PRODUCTS AND CHEMICALS', 'AKAMAI TECHNOLOGIES',  'ALBEMARLE CORPORATION',\n",
        "# 'ALEXION PHARMACEUTICALS',  'Allergan plc', 'ALLIANT ENERGY CORPORATION', 'ALPHABET', 'Altria Group', 'AMAZON',\n",
        "# 'AMEREN CORPORATION', 'AMERICAN AIRLINES GROUP', 'AMERICAN ELECTRIC POWER COMPANY', 'AMERICAN EXPRESS COMPANY'\n",
        "# 'AMERICAN INTERNATIONAL GROUP', 'AMERICAN WATER WORKS COMPANY', 'AMERIPRISE FINANCIAL',  'AMERISOURCEBERGEN CORPORATION'\n",
        "# 'AMETEK', 'AMGEN', 'AMPHENOL CORPORATION', 'ANALOG DEVICES', 'ANSYS',  'ANTHEM',  'AON',\n",
        "# 'APACHE CORPORATION', 'APPLE', 'APPLIED MATERIALS', 'ARCHER-DANIELS-MIDLAND COMPANY',\n",
        "# 'ARTHUR J. GALLAGHER & CO', 'ASSURANT', 'AT&T', 'AUTODESK', 'AUTOMATIC DATA PROCESSING','AUTOZONE', 'AVERY DENNISON CORPORATION',\n",
        "# 'BALL CORPORATION', 'BANK OF AMERICA CORPORATION', 'BAXTER INTERNATIONAL', 'BECTON', 'DICKINSON AND COMPANY']\n",
        "\n",
        "companies = ['NEWS CORPORATION', 'NEXTERA ENERGY', 'NIELSEN HOLDINGS PLC', 'NIKE', 'NORFOLK SOUTHERN CORPORATION', 'NORTHERN TRUST CORPORATION', \n",
        "              'Northrop Grumman Corporation', 'NORWEGIAN CRUISE LINE HOLDINGS', 'NUCOR CORPORATION', 'NVIDIA CORPORATION']\n",
        "\n",
        "techniques = ['Descriptive Analytics', 'Predictive Analytics', 'Prescriptive Analytics', 'Association analysis', 'Market Basket Analysis', 'Cooccurence Grouping', 'Association Rule Mining', 'Association Discovery', \n",
        "                'Sequence analysis', 'Sequential Pattern Mining', 'Clustering', 'Cluster analysis', 'Similarity matching', 'Link analysis',\n",
        "              'decision tree', 'decision trees', 'neural networks', 'neural network','Partial Least Squares Regression', 'LARS', 'Random Forest', 'Gradient Boosting',  'Suport Vector Machines',\n",
        " 'Genetic Algorithms', 'Prescriptive Analytics', 'Stochastic Optimization', 'Optimization', 'Multi Criteria Decision Making Techniques'\n",
        " , 'Decision Modeling', 'Network Science', 'Simulation Techniques', 'Deep Learning', 'Artificial Intelligence']\n",
        "\n",
        "for i in range(len(files)):\n",
        "  path = '/content/gdrive/MyDrive/test1Texts/{}'.format(files[i])\n",
        "  for company in companies:\n",
        "    line = search_string_in_file(path, company)\n",
        "    if line:\n",
        "      for technique in techniques:\n",
        "        line1 = search_string_in_file(path, technique)\n",
        "        if line1 != []:\n",
        "            print(files[i], ' Company ', company, ' Technique ', technique, line,  line1)\n",
        "            \n",
        "    else:\n",
        "      #line1 = 0\n",
        "      #print(\"No match\")\n",
        "      pass\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an0UGMTn8YLz"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "files = [f for f in listdir('/content/gdrive/MyDrive/test2Texts') if isfile(join('/content/gdrive/MyDrive/test2Texts', f))]\n",
        "\n",
        "# companies = ['3M Company', 'A.O.Smith Corporation', 'Abbott Laboratories', 'Abbvie Inc.', 'Accenture Public Limited', 'Activision Blizzard Inc.',\n",
        "#             'Advance Auto Parts', 'Advanced Micro Devices', 'Aflac Inc', 'Accenture', 'AGILENT TECHNOLOGIES ', 'AIR PRODUCTS AND CHEMICALS', 'AKAMAI TECHNOLOGIES',  'ALBEMARLE CORPORATION',\n",
        "# 'ALEXION PHARMACEUTICALS',  'Allergan plc', 'ALLIANT ENERGY CORPORATION', 'ALPHABET', 'Altria Group', 'AMAZON',\n",
        "# 'AMEREN CORPORATION', 'AMERICAN AIRLINES GROUP', 'AMERICAN ELECTRIC POWER COMPANY', 'AMERICAN EXPRESS COMPANY'\n",
        "# 'AMERICAN INTERNATIONAL GROUP', 'AMERICAN WATER WORKS COMPANY', 'AMERIPRISE FINANCIAL',  'AMERISOURCEBERGEN CORPORATION'\n",
        "# 'AMETEK', 'AMGEN', 'AMPHENOL CORPORATION', 'ANALOG DEVICES', 'ANSYS',  'ANTHEM',  'AON',\n",
        "# 'APACHE CORPORATION', 'APPLE', 'APPLIED MATERIALS', 'ARCHER-DANIELS-MIDLAND COMPANY',\n",
        "# 'ARTHUR J. GALLAGHER & CO', 'ASSURANT', 'AT&T', 'AUTODESK', 'AUTOMATIC DATA PROCESSING','AUTOZONE', 'AVERY DENNISON CORPORATION',\n",
        "# 'BALL CORPORATION', 'BANK OF AMERICA CORPORATION', 'BAXTER INTERNATIONAL', 'BECTON', 'DICKINSON AND COMPANY']\n",
        "\n",
        "companies = ['NEWS CORPORATION', 'NEXTERA ENERGY', 'NIELSEN HOLDINGS PLC', 'NIKE', 'NORFOLK SOUTHERN CORPORATION', 'NORTHERN TRUST CORPORATION', \n",
        "              'Northrop Grumman Corporation', 'NORWEGIAN CRUISE LINE HOLDINGS', 'NUCOR CORPORATION', 'NVIDIA CORPORATION']\n",
        "\n",
        "techniques = ['Descriptive Analytics', 'Predictive Analytics', 'Prescriptive Analytics','Association analysis', 'Market Basket Analysis', 'Cooccurence Grouping', 'Association Rule Mining', 'Association Discovery', \n",
        "                'Sequence analysis', 'Sequential Pattern Mining', 'Clustering', 'Cluster analysis', 'Similarity matching', 'Link analysis',\n",
        "              'decision tree', 'decision trees', 'neural networks', 'neural network','Partial Least Squares Regression', 'LARS', 'Random Forest', 'Gradient Boosting',  'Suport Vector Machines',\n",
        " 'Genetic Algorithms', 'Prescriptive Analytics', 'Stochastic Optimization', 'Optimization', 'Multi Criteria Decision Making Techniques'\n",
        " , 'Decision Modeling', 'Network Science', 'Simulation Techniques', 'Deep Learning', 'Artificial Intelligence']\n",
        "\n",
        "for i in range(len(files)):\n",
        "  path = '/content/gdrive/MyDrive/test2Texts/{}'.format(files[i])\n",
        "  for company in companies:\n",
        "    line = search_string_in_file(path, company)\n",
        "    if line:\n",
        "      for technique in techniques:\n",
        "        line1 = search_string_in_file(path, technique)\n",
        "        if line1 != []:\n",
        "            print(files[i], ' Company ', company, ' Technique ', technique, line,  line1)\n",
        "            \n",
        "    else:\n",
        "      #line1 = 0\n",
        "      #print(\"No match\")\n",
        "      pass\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5KdHLpwMbIc"
      },
      "source": [
        "l = search_string_in_file(\"/content/gdrive/MyDrive/test1Texts/{}.txt\".format(base), \"International\" )\n",
        "print(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpGuIPGDDAPr"
      },
      "source": [
        "import re\n",
        "\n",
        "file = open('C:\\Users\\swetha\\content.txt', encoding=\"utf-8\")\n",
        "read_file = file.read()\n",
        "\n",
        "companies = ['3M Company', 'A.O.Smith Corporation', 'Abbott Laboratories', 'Abbvie Inc.', 'Accenture Public Limited', 'Activision Blizzard Inc.',\n",
        "            'Advance Auto Parts Inc.', 'Advanced Micro Devices Inc.', 'Aflac Inc', 'Netflix used' ]\n",
        "\n",
        "techniques = ['Association analysis', 'Market Basket Analysis', 'Cooccurence Grouping', 'Association Rule Mining', 'Association Discovery', \n",
        "                'Sequence analysis', 'Sequential Pattern Mining', 'Clustering', 'Cluster analysis', 'Similarity matching', 'Link analysis']\n",
        "\n",
        "def is_phrase_in(phrase, text):\n",
        "    return re.search(r\"\\b{}\\b\".format(phrase), text, re.IGNORECASE) is not None\n",
        "\n",
        "\n",
        "for company in companies:\n",
        "    phrase = company\n",
        "    if is_phrase_in(phrase, read_file):\n",
        "        print('True')\n",
        "    else:\n",
        "        print(\"False\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ji8XAFdOIitk",
        "outputId": "8924a2a6-f216-4bb3-e81d-260ffcd9ebd4"
      },
      "source": [
        "import os\n",
        "base = os.path.splitext(fichiers1[0])[0]\n",
        "base"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Geospatial big data handling with high performance computing: Current approaches and future directions'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Dpcbs7G9sV",
        "outputId": "c9277ec5-ae16-4c66-8926-daf5dd9b8648"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "file = open(\"/content/gdrive/MyDrive/test1Texts/{}.txt\".format(base), encoding=\"utf-8\")\n",
        "read_file = file.read()\n",
        "raw = nltk.word_tokenize(read_file)\n",
        "text = nltk.Text(read_file)\n",
        "\n",
        "match = text.concordance('Jordan')\n",
        "print(match)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "No matches\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV-SvUynPhUa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}